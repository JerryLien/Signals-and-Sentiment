# PTT Signals and Sentiment

å— [ICE Reddit Signals and Sentiment](https://www.ice.com/) å•Ÿç™¼çš„ PTT è‚¡æ¿æƒ…ç·’åˆ†æå·¥å…·ã€‚

å¾ PTT ç¶²é ç‰ˆ (www.ptt.cc) çˆ¬å–æ–‡ç« èˆ‡æ¨æ–‡ï¼Œé€éæ¨/å™“åŠ æ¬Šè¨ˆåˆ†ç”¢ç”Ÿæƒ…ç·’æŒ‡æ¨™ï¼Œä¸¦è‡ªå‹•è¾¨è­˜æ–‡ä¸­æåŠçš„å°è‚¡æ¨™çš„ã€‚

## æ¶æ§‹

```
ptt_scraper/
â”œâ”€â”€ scraper.py          # çˆ¬èŸ²æ ¸å¿ƒ â€” æŠ“å–æ–‡ç« åˆ—è¡¨ã€å…§æ–‡ã€æ¨æ–‡
â”œâ”€â”€ sentiment.py        # æƒ…ç·’åˆ†æ â€” æ¨/å™“/â†’ åŠ æ¬Šè¨ˆåˆ†
â”œâ”€â”€ entity_mapping.py   # å¯¦é«”è¾¨è­˜ â€” PTT æš±ç¨± â†’ è­‰åˆ¸ä»£ç¢¼
â””â”€â”€ config.py           # è¨­å®šå¸¸æ•¸ (URLã€Headersã€æ¬Šé‡)
main.py                 # CLI å…¥å£
```

## å®‰è£

```bash
pip install -r requirements.txt
```

éœ€è¦ Python 3.10+ã€‚

## ä½¿ç”¨æ–¹å¼

```bash
# é è¨­çˆ¬ Stock ç‰ˆæœ€æ–° 1 é 
python main.py

# çˆ¬ 3 é ï¼Œä»¥ JSON è¼¸å‡º
python main.py --pages 3 --json

# æŒ‡å®šçœ‹æ¿èˆ‡è«‹æ±‚é–“éš”
python main.py --board Gossiping --pages 2 --delay 1.0
```

### CLI åƒæ•¸

| åƒæ•¸ | é è¨­å€¼ | èªªæ˜ |
|------|--------|------|
| `--board` | `Stock` | ç›®æ¨™çœ‹æ¿ |
| `--pages` | `1` | å¾€å‰çˆ¬å¹¾é  |
| `--delay` | `0.5` | æ¯æ¬¡è«‹æ±‚é–“éš”ç§’æ•¸ |
| `--json` | off | ä»¥ JSON æ ¼å¼è¼¸å‡º |

### è¼¸å‡ºç¯„ä¾‹

**è¡¨æ ¼æ¨¡å¼ï¼ˆé è¨­ï¼‰ï¼š**

```
æ¨™é¡Œ                                     æƒ…ç·’      æ¨   å™“   â†’  ç›¸é—œæ¨™çš„
------------------------------------------------------------------------------------------
[è«‹ç›Š] GGé‚„èƒ½è¿½å—                         ğŸŸ¢çœ‹å¤š   12    1    5  2330(å°ç©é›»)
[é–’èŠ] èˆªé‹ä¸‰é›„ä»Šå¤©æ€éº¼äº†                  ğŸ”´çœ‹ç©º    3    8    4  2603(é•·æ¦®), 2609(é™½æ˜), 2615(è¬æµ·)
------------------------------------------------------------------------------------------
å…± 2 ç¯‡ | çœ‹å¤š: 1 | çœ‹ç©º: 1 | ä¸­æ€§: 0
```

**JSON æ¨¡å¼ (`--json`)ï¼š**

```json
[
  {
    "title": "[è«‹ç›Š] GGé‚„èƒ½è¿½å—",
    "url": "https://www.ptt.cc/bbs/Stock/M.1234567890.A.123.html",
    "author": "stock_man",
    "date": "Wed Feb  5 10:30:00 2026",
    "sentiment": {
      "score": 10.5,
      "label": "bullish",
      "push": 12,
      "boo": 1,
      "arrow": 5
    },
    "entities": [
      { "ticker": "2330", "name": "å°ç©é›»", "matched": "gg" }
    ]
  }
]
```

## æƒ…ç·’è¨ˆåˆ†æ–¹å¼

åŸºæ–¼æ¨æ–‡æ¨™ç±¤çš„åŠ æ¬Šåˆ†æ•¸ï¼š

| æ¨™ç±¤ | æ„ç¾© | æ¬Šé‡ |
|------|------|------|
| æ¨ | çœ‹å¤š / æ­£é¢ | +1.0 |
| å™“ | çœ‹ç©º / è² é¢ | -1.5 |
| â†’ | ä¸­æ€§è£œå…… | 0.0 |

**åˆ†é¡è¦å‰‡ï¼š**
- `score >= 2.0` â†’ bullishï¼ˆçœ‹å¤šï¼‰
- `score <= -2.0` â†’ bearishï¼ˆçœ‹ç©ºï¼‰
- å…¶é¤˜ â†’ neutralï¼ˆä¸­æ€§ï¼‰

> å™“çš„æ¬Šé‡è¼ƒé«˜ï¼ˆ-1.5ï¼‰æ˜¯å› ç‚ºåœ¨è‚¡æ¿ä¸­ï¼Œå™“é€šå¸¸ä»£è¡¨æ›´å¼·çƒˆçš„è² é¢æ…‹åº¦ã€‚

## å¯¦é«”è¾¨è­˜ (Entity Mapping)

é¡ä¼¼ ICE å°‡ Reddit ä¸Šçš„ "Micky Mouse" å°æ‡‰åˆ° Disney tickerï¼Œæœ¬å·¥å…·å°‡ PTT é„‰æ°‘æ…£ç”¨çš„æš±ç¨±å°æ‡‰åˆ°å°è‚¡è­‰åˆ¸ä»£ç¢¼ï¼š

| æš±ç¨± | ä»£ç¢¼ | å…¬å¸ |
|------|------|------|
| GGã€ç¥å±±ã€è­·åœ‹ç¥å±±ã€å°GG | 2330 | å°ç©é›» |
| éƒ­è‘£ã€åœŸåŸéµã€æµ·å…¬å…¬ | 2317 | é´»æµ· |
| ç™¼å“¥ã€MTK | 2454 | è¯ç™¼ç§‘ |
| å¤§ç›¤ã€åŠ æ¬Š | TAIEX | åŠ æ¬ŠæŒ‡æ•¸ |
| ... | ... | ... |

å®Œæ•´å°æ‡‰è¡¨è¦‹ [`entity_mapping.py`](ptt_scraper/entity_mapping.py)ã€‚ä¹Ÿæ”¯æ´ç›´æ¥è¾¨è­˜ç´”æ•¸å­—ä»£ç¢¼ï¼ˆå¦‚ `2330`ã€`2330.TW`ï¼‰ã€‚

å¯é€é `EntityMapper(extra_aliases={...})` æ“´å……è‡ªè¨‚æš±ç¨±ã€‚

## ä½œç‚ºæ¨¡çµ„ä½¿ç”¨

```python
from ptt_scraper import PttScraper, SentimentScorer, EntityMapper

scraper = PttScraper(board="Stock")
posts = scraper.fetch_posts(max_pages=2)

scorer = SentimentScorer()
mapper = EntityMapper()

for post in posts:
    result = scorer.analyze_post(post)
    entities = mapper.find_entities(post.title + " " + post.content)
    print(f"{post.title} â†’ {result.label} (score={result.score})")
    print(f"  æåŠ: {[e['ticker'] for e in entities]}")
```

## License

MIT
