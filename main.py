#!/usr/bin/env python3
"""PTT è‚¡æ¿æƒ…ç·’åˆ†æ â€” å— ICE Reddit Signals and Sentiment å•Ÿç™¼ã€‚

ç”¨æ³•:
    python main.py                      # é è¨­çˆ¬ Stock ç‰ˆ 1 é 
    python main.py --board Gossiping --pages 3
"""

import argparse
import json
import sys

from ptt_scraper import EntityMapper, PttScraper, SentimentScorer


def main() -> None:
    parser = argparse.ArgumentParser(
        description="PTT Signals and Sentiment â€” çˆ¬å– PTT æ–‡ç« ä¸¦åˆ†ææƒ…ç·’",
    )
    parser.add_argument(
        "--board", default="Stock", help="ç›®æ¨™çœ‹æ¿ (é è¨­: Stock)",
    )
    parser.add_argument(
        "--pages", type=int, default=1, help="è¦çˆ¬å¹¾é  (é è¨­: 1)",
    )
    parser.add_argument(
        "--delay", type=float, default=0.5, help="æ¯æ¬¡è«‹æ±‚é–“éš”ç§’æ•¸ (é è¨­: 0.5)",
    )
    parser.add_argument(
        "--json", action="store_true", help="ä»¥ JSON æ ¼å¼è¼¸å‡ºçµæœ",
    )
    args = parser.parse_args()

    scraper = PttScraper(board=args.board, delay=args.delay)
    scorer = SentimentScorer()
    mapper = EntityMapper()

    print(f"æ­£åœ¨çˆ¬å– PTT {args.board} ç‰ˆ (å…± {args.pages} é )...\n")
    posts = scraper.fetch_posts(max_pages=args.pages)

    if not posts:
        print("æœªæŠ“åˆ°ä»»ä½•æ–‡ç« ã€‚")
        sys.exit(0)

    results = []
    for post in posts:
        sentiment = scorer.analyze_post(post)
        entities = mapper.find_entities(post.title + " " + post.content)

        results.append({
            "title": post.title,
            "url": post.url,
            "author": post.author,
            "date": post.date,
            "sentiment": {
                "score": sentiment.score,
                "label": sentiment.label,
                "push": sentiment.push_count,
                "boo": sentiment.boo_count,
                "arrow": sentiment.arrow_count,
            },
            "entities": entities,
        })

    if args.json:
        print(json.dumps(results, ensure_ascii=False, indent=2))
    else:
        _print_table(results)


def _print_table(results: list[dict]) -> None:
    """ä»¥æ˜“è®€çš„è¡¨æ ¼æ–¹å¼å°å‡ºçµæœã€‚"""
    print(f"{'æ¨™é¡Œ':<40} {'æƒ…ç·’':>8} {'æ¨':>4} {'å™“':>4} {'â†’':>4} {'ç›¸é—œæ¨™çš„'}")
    print("-" * 90)
    for r in results:
        s = r["sentiment"]
        title = r["title"][:38]
        entities_str = ", ".join(
            f"{e['ticker']}({e['name']})" if e["name"] else e["ticker"]
            for e in r["entities"]
        )
        label = {
            "bullish": "ğŸŸ¢çœ‹å¤š",
            "bearish": "ğŸ”´çœ‹ç©º",
            "neutral": "âšªä¸­æ€§",
        }.get(s["label"], s["label"])

        print(
            f"{title:<40} {label:>8} {s['push']:>4} {s['boo']:>4} {s['arrow']:>4} {entities_str}"
        )

    # ç¸½çµ
    total = len(results)
    bullish = sum(1 for r in results if r["sentiment"]["label"] == "bullish")
    bearish = sum(1 for r in results if r["sentiment"]["label"] == "bearish")
    neutral = total - bullish - bearish
    print("-" * 90)
    print(f"å…± {total} ç¯‡ | çœ‹å¤š: {bullish} | çœ‹ç©º: {bearish} | ä¸­æ€§: {neutral}")


if __name__ == "__main__":
    main()
